{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CLIP Multimodal RAG — Demo\n",
        "\n",
        "This notebook runs the **multimodal RAG** pipeline from the `clip_multimodal_rag` package: it indexes a PDF (text + images) with **CLIP**, retrieves relevant chunks with **FAISS**, and generates answers with **Google Gemini**.\n",
        "\n",
        "Run the cells in order. Ensure `.env` contains `GOOGLE_API_KEY` and the PDF path below exists.\n",
        "\n",
        "\n"
      ],
      "id": "8f4a9611"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure package is importable when notebook is run from project root\n",
        "import sys\n",
        "from pathlib import Path\n",
        "root = Path.cwd()\n",
        "if str(root / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(root / \"src\"))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from clip_multimodal_rag import (\n",
        "    CLIPEmbedder,\n",
        "    PDFProcessor,\n",
        "    MultimodalRetriever,\n",
        "    MultimodalRAGPipeline,\n",
        ")\n",
        "from clip_multimodal_rag.config import get_google_api_key, CLIP_MODEL_ID, GEMINI_MODEL"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          }
        }
      ],
      "id": "bcde5fab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Require Google API key for Gemini\n",
        "get_google_api_key()\n",
        "print(\"GOOGLE_API_KEY found.\")"
      ],
      "execution_count": 2,
      "outputs": [],
      "id": "d5a29f04"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load CLIP and process PDF\n",
        "embedder = CLIPEmbedder(model_id=CLIP_MODEL_ID)\n",
        "processor = PDFProcessor(chunk_size=500, chunk_overlap=100, embedder=embedder)\n",
        "\n",
        "pdf_path = \"CV_HZolfaghari_new.pdf\"  # Change to your PDF\n",
        "docs, embeddings, image_store = processor.process(pdf_path)\n",
        "print(f\"Indexed {len(docs)} chunks (text + images).\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "CLIP model loaded!\n"
          ]
        }
      ],
      "id": "5bbbcd1b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build retriever and RAG pipeline\n",
        "retriever = MultimodalRetriever(embedder, docs, embeddings)\n",
        "pipeline = MultimodalRAGPipeline(\n",
        "    embedder, retriever, image_store,\n",
        "    gemini_model=GEMINI_MODEL,\n",
        "    top_k=5,\n",
        ")\n",
        "print(\"Pipeline ready. Use pipeline.query('Your question') to run RAG.\")"
      ],
      "execution_count": 4,
      "outputs": [],
      "id": "53b4a75d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect indexed documents (optional)\n",
        "print(f\"Sample text chunk: {docs[0].page_content[:150]}...\")\n",
        "print(f\"Image store keys: {list(image_store.keys())[:5]}...\")"
      ],
      "execution_count": 5,
      "outputs": [],
      "id": "6eb35d72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: single query\n",
        "answer = pipeline.query(\"Summarize the main findings from the document.\")\n",
        "print(\"Answer:\", answer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document('CV_HZolfaghari_new.pdf')"
            ]
          }
        }
      ],
      "id": "3e146181"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run multiple example queries\n",
        "queries = [\n",
        "    \"Summarize the main findings from the document\",\n",
        "    \"What visual elements are present in the document?\",\n",
        "]\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"-\" * 50)\n",
        "    print(pipeline.query(q, verbose=True))\n",
        "    print(\"=\" * 70)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 0, 'type': 'text'}, page_content='Hossein Zolfaghari\\nAI/ML Engineer\\nParis, France\\nOpen to relocation\\n\\x83 (+33) 0753142705\\n# hossein.xolf@gmail.com\\nï LinkedIn\\n§ GitHub\\nAbout Me\\nMachine Learning Engineer with 5+ years of experience building and deploying AI solutions across cloud and edge\\ndevices. I specialize in multimodal deep learning, Generative AI, and MLOps, with a strong focus on delivering models\\nthat reliably move from prototype to production. I enjoy designing scalable pipelines, improving model performance, and'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='collaborating with teams to turn complex ideas into practical, high-impact systems. I stay aligned with the latest AI\\nadvancements while keeping solutions simple, efficient, and production-ready.\\nWork Experiences\\n• Machine Learning Engineer\\n2023 – 2025\\nSESA\\nPerpignan, France\\n– Developed a hybrid multimodal machine learning model for large time-series datasets with 96% accuracy, improving\\nforecasting performance and supporting decision-making system.'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='forecasting performance and supporting decision-making system.\\n– Implemented a YOLO-based computer vision service to monitor grape growth stages in vineyard imagery, enabling\\nmore accurate crop condition tracking and supporting decision maker software.\\n– Contributed to an intelligent PV panel system that uses AI-based decision maker model to dynamically adjust panel\\norientation based on environmental and operational conditions, resulting in improving energy capture efficiency.'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='– Designed and maintained a CI/CD pipeline using GitHub Actions and AWS ECR, enabling reproducible model\\ndeployment on edge devices (Raspberry Pi).\\n• Machine Learning Engineer\\n2022 – 2023\\nSATT AXLR\\nMontpellier, France\\n– Contributed to the design and deployment of a real-time AI service for cloud detection and motion estimation (speed\\nand direction) in sky images, which improved prediction accuracy by 3%.'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='and direction) in sky images, which improved prediction accuracy by 3%.\\n– Worked on a YOLO-based object detection pipeline to identify raindrops and other visual artifacts in fisheye camera.\\n– Built an interactive Grafana dashboard to monitor data pipelines, models outputs, and performance metrics.\\n• Machine Learning Engineer\\n2022\\nPROMES-CNRS\\nPerpignan, France\\n– Developed a high-precision solar irradiance forecasting model by applying advanced time-series techniques and'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='feature engineering. The approach improved forecast accuracy by 5% over the previous model.\\n– Created a sky-state estimation model using multi-modal environmental and imaging data, achieving over 90%\\nclassification accuracy.\\n• AI Engineer\\n2020 – 2021\\nDARVIZ\\nTehran, Iran\\n– Built AI recommendation system serving 150K+ users with personalized content delivery.\\n– Developed NLP pipeline for document processing handling 10K+ documents daily.\\n• Data Analyst\\n2018 – 2020\\nIUT\\nIsfahan, Iran'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='• Data Analyst\\n2018 – 2020\\nIUT\\nIsfahan, Iran\\n– Applied stochastic modeling and uncertainty quantification to build predictive models, improving accuracy by 25%.\\n– Conducted comprehensive sensitivity and sampling analyses (Sobol indices, LHS) to evaluate model robustness and\\nparameter impact, contributing to two publications, [1, 2].\\nEducation\\n• University of Paris-Saclay | M.Sc. in Computer Vision and Artificial Intelligence\\nParis, France | 2021 - 2022'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='Paris, France | 2021 - 2022\\nThesis: Benchmarking Vision Transformers and CNNs for Multi-Modal Intra-Hour Solar Irradiance Forecasting.\\n• Isfahan University of Technology | M.Sc. in Engineering\\nIsfahan, Iran | 2014 - 2017\\n• K.N.Toosi University of Technology | B.Sc. in Engineering\\nTehran, Iran | 2009 - 2013'),\n",
              " Document(metadata={'page': 1, 'type': 'text'}, page_content='Techincal Skills\\n• Generative AI & LLMs: Transformers, Multimodal\\nAI, Agentic AI, LangChain, RAG, CrewAI, LangGraph,\\nHuggingFace, Amazon Bedrock, Prompt & Context En-\\ngineering, Fine-Tuning\\n• ML\\nTools:\\nPyTorch,\\nTensorFlow,\\nScikit-learn,\\nOpenCV, CNN, LSTM, YOLO, Feature Engineering,\\nModel Optimization\\n• MLOps & Deployment: CI/CD (GitHub Actions),\\nDocker, AWS (EC2, S3, ECR), GCP, MLflow, FastAPI,\\nFlask, Git, Monitoring (Grafana, Zabbix), Edge Deploy-\\nment (Raspberry Pi)'),\n",
              " Document(metadata={'page': 1, 'type': 'text'}, page_content='Flask, Git, Monitoring (Grafana, Zabbix), Edge Deploy-\\nment (Raspberry Pi)\\n• Databases: PostgreSQL, MongoDB, SQLite, MySQL\\n• Programming: Python (+7 yrs), SQL\\nSoft Skills\\n• Leadership: Taking ownership of projects, guiding technical decisions, and supporting teammates when needed.\\nExperienced in working closely with cross-functional teams.\\n• Communication: Able to explain complex ML ideas in a clear and practical way to both technical and non-technical\\naudiences.'),\n",
              " Document(metadata={'page': 1, 'type': 'text'}, page_content='audiences.\\n• Project Management: Organized and reliable when managing multiple projects, setting priorities, and meeting\\ndeadlines.\\n• Problem-Solving: Strong analytical mindset with a creative approach to finding solutions. Detail-oriented, commit-\\nted to quality, and always learning new tools or methods to improve my work.\\nSelected Certificates\\n• Coursera | 2023, Generative AI with LLMs.\\n• AWS | 2022, AWS Cloud Practitioner.\\n• Udemy | 2020, Data Science and ML in Python.'),\n",
              " Document(metadata={'page': 1, 'type': 'text'}, page_content='• AWS | 2022, AWS Cloud Practitioner.\\n• Udemy | 2020, Data Science and ML in Python.\\n• Coursera | 2021, Structuring ML Projects.\\n• Coursera\\n|\\n2019, Neural Networks and DL with\\nPython.\\nHonors & Awards\\n• Top 1%, Nationwide M.Sc. entrance exam in engineering (Konkour), with more than 25,000 participants, 2013, Iran.\\n• Top 0.5%, National entrance exam of Iran universities (Konkour), among more than 280,000 participants, 2009, Iran.\\nLanguages'),\n",
              " Document(metadata={'page': 1, 'type': 'text'}, page_content='Languages\\n• Languages: English: Fluent, French: Intermediate, Persian: Native')]"
            ]
          }
        }
      ],
      "id": "afd57f98"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add your own queries here\n",
        "# pipeline.query(\"Your question here\")"
      ],
      "execution_count": 8,
      "outputs": [],
      "id": "a4aa87d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: save/load index (see package docs for persistence)\n",
        "# retriever._store.save_local(\"index\"); FAISS.load_local(\"index\", _FakeEmbeddings(...))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ],
      "id": "c2fa6cae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": 10,
      "outputs": [],
      "id": "2c899cc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": 11,
      "outputs": [],
      "id": "98f3c2ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": 12,
      "outputs": [],
      "id": "983f15b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": 13,
      "outputs": [],
      "id": "217a24df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Done. Use pipeline.query(\"...\") for more questions."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Summarize the main findings from the document\n",
            "--------------------------------------------------\n",
            "\n",
            "Retrieved 5 documents:\n",
            "  - Text from page 1: Languages\n",
            "• Languages: English: Fluent, French: Intermediate, Persian: Native\n",
            "  - Text from page 1: • AWS | 2022, AWS Cloud Practitioner.\n",
            "• Udemy | 2020, Data Science and ML in Python.\n",
            "• Coursera | 20...\n",
            "  - Text from page 1: Techincal Skills\n",
            "• Generative AI & LLMs: Transformers, Multimodal\n",
            "AI, Agentic AI, LangChain, RAG, Cr...\n",
            "  - Text from page 0: collaborating with teams to turn complex ideas into practical, high-impact systems. I stay aligned w...\n",
            "  - Text from page 0: feature engineering. The approach improved forecast accuracy by 5% over the previous model.\n",
            "– Create...\n",
            "\n",
            "\n",
            "Answer: The document describes an experienced Machine Learning and AI Engineer with a strong background in developing and deploying high-impact, production-ready AI systems.\n",
            "\n",
            "Key findings include:\n",
            "*   **Extensive Technical Expertise:** Proficient in Generative AI, LLMs (Transformers, LangChain, RAG, HuggingFace, Amazon Bedrock), core ML tools (PyTorch, TensorFlow, Scikit-learn, CNN, LSTM, YOLO), and MLOps/Deployment (CI/CD, Docker, AWS, GCP, MLflow, FastAPI).\n",
            "*   **Practical Project Experience:** Developed a hybrid multimodal ML model achieving 96% accuracy for time-series forecasting, created a sky-state estimation model with over 90% accuracy, built an AI recommendation system serving 150K+ users, and developed an NLP pipeline processing 10K+ documents daily.\n",
            "*   **Certifications & Academic Excellence:** Holds an AWS Cloud Practitioner certification and completed several advanced ML/DL courses. Achieved top 1% and 0.5% in highly competitive national entrance exams in Iran for M.Sc. and university admission, respectively.\n",
            "*   **Multilingual:** Fluent in English, native in Persian, and intermediate in French.\n",
            "======================================================================\n",
            "\n",
            "Query: What visual elements are present in the document?\n",
            "--------------------------------------------------\n",
            "\n",
            "Retrieved 5 documents:\n",
            "  - Text from page 1: Languages\n",
            "• Languages: English: Fluent, French: Intermediate, Persian: Native\n",
            "  - Text from page 1: Techincal Skills\n",
            "• Generative AI & LLMs: Transformers, Multimodal\n",
            "AI, Agentic AI, LangChain, RAG, Cr...\n",
            "  - Text from page 1: • AWS | 2022, AWS Cloud Practitioner.\n",
            "• Udemy | 2020, Data Science and ML in Python.\n",
            "• Coursera | 20...\n",
            "  - Text from page 0: collaborating with teams to turn complex ideas into practical, high-impact systems. I stay aligned w...\n",
            "  - Text from page 0: – Designed and maintained a CI/CD pipeline using GitHub Actions and AWS ECR, enabling reproducible m...\n",
            "\n",
            "\n",
            "Answer: Based on the provided text excerpts, the following visual elements related to document formatting and structure are present:\n",
            "\n",
            "*   **Headings/Section Titles:** Examples include \"Languages,\" \"Technical Skills,\" \"Honors & Awards,\" and \"Work Experiences.\" These clearly delineate different sections of the document.\n",
            "*   **Bullet Points:** The consistent use of the \"•\" symbol indicates that information is presented in bulleted lists (e.g., listing languages, technical skills, certifications, and responsibilities).\n",
            "*   **Paragraphs/Text Blocks:** The introductory statement and the detailed descriptions under work experiences are structured as distinct blocks of text.\n",
            "======================================================================\n"
          ]
        }
      ],
      "id": "fb921b25"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "new_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}